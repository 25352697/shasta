<!DOCTYPE html>
<html>

<head>
<link rel=stylesheet href=style.css />
<link rel=icon href=CZI-new-logo.png />
</head>


<body>

<h1>GitHub repository 
<a href="https://github.com/chanzuckerberg/shasta">chanzuckerberg/shasta</a>
</h1>



<h2>Motivation and wish list</h2>

<p>
It was  
<a href="https://www.nature.com/articles/nbt.4060"> recently shown</a>
that <i>de novo</i> assembly for human genomes
from <a href="https://nanoporetech.com">Oxford Nanopore</a> reads
is possible, but computationally expensive and laborious.
The aim of this project is to
make <i>de novo</i> assembly of human genomes
possible on a routine/production basis and at reasonable 
computational cost.

For this to be possible, <i>de novo</i> assembly must be:

<ul>
<li>Fast: under one day elapsed time.
<li>Accurate: accuracy and other assembly metrics 
comparable to those provided by existing tools.
<li>Logistically simple and easy to run. 
</ul>

<p>
This project is at an early stage, and does not yet produce
assembled sequence as its final output.
Contributions of code, ideas, computational experiments,
or documentation are welcome. 
To contribute, please use the standard GitHub Pull Request process.
To facilitate and encourage contributions, the 
<a href=CONTRIBUTING.html>guidelines</a>
for contributing are minimal.

<p>
Comments and criticism are also welcome.
Please use the GitHub 
<a href="https://github.com/chanzuckerberg/shasta/wiki">Wiki</a>
or 
<a href="https://github.com/chanzuckerberg/shasta/issues">Issues</a>
sections of the GitHub repository as appropriate for these purposes.



<h2>Computational approach</h2>

<p>
See <a href=ShastaSlides-June2018-v2.pdf>this presentation</a>
for information on the computational approach selected.
In addition to Oxford Nanopore reads,
these methods might also apply to other long reads with high 
error rates such as those created by the
<a href="https://www.pacb.com/">Pacific Biosciences</a> DNA sequencing platforms.

<p>
In the chosen computational approach, 
an assembly runs in memory on a single, dedicated large machine 
with a large amount of memory (&asymp; 1 TB)
and a relatively large number of processors (&asymp; 32 cores). 
Input data are copied to memory, the entire assembly runs
in memory without disk access (except for log files
and small summary files), and the output is finally copied
to storage. This minimizes delays due to data movement,
and facilitates algorithmic development, as all data
structures are always loaded in memory and immediately
accessible.

<p>
The requirement for such a large machine may seem extravagant.
However, machines with these characteristics are
currently easily available at reasonable prices on the major
cloud computing platforms. 
For example, on 
<a href="https://aws.amazon.com/ec2">AWS EC2</a>, 
instance type <code>x1.16xlarge</code>,
with 976 GB of memory and 32 cores (64 "virtual processors"
because of hyperthreading)
is available at the time of writing for an hourly price around 
$7 (on demand pricing), 
$4 (reserved pricing), 
$2 (spot pricing).
And on <a href="https://cloud.google.com">Google Cloud</a>, 
machine type <code>n1-ultramem-40</code>, 
with similar characteristics,
is available at similar prices.
And machines with 1-2 TB of memory are often available
as departmental machines.



<h2>Supported platform</h2>
<p>
The code is currently set up to build and run on Ubuntu 16.04.
The documentation assumes that this is the platform used
both for building and running the code.

<p> 
Porting to other Linux systems should be relatively easy,
and likely requiring just minor changes to the build process.
However this has not yet been attempted. 
If you are interested in portability to a specific Linux platform,
please open a 
<a href="https://github.com/chanzuckerberg/shasta/issues">GitHub Issue</a> 
on the repository.



<h2>Building the code from source</h2>
<p>
This section, as the rest of the documentation,
assumes that you are on an Ubuntu 16.04 machine.

<p>
If you have the necessary 
<a href=Prerequisites.html>prerequisite packages</a> installed, 
you can get a local copy of the code and build it
using the following commands: 
<pre>
git clone git@github.com:chanzuckerberg/shasta.git
mkdir shasta-build
cd shasta-build
cmake ../shasta
make all
make install
</pre>

<p>
If you are not sure if you have the necessary prerequisite packages installed, 
you can instead
use the following commands
(this assumes that you are authorized to acquire root privileges
using the <code>sudo</code> command - depending on set up you may be asked 
to enter your password):
<pre>
git clone git@github.com:chanzuckerberg/shasta.git
sudo shasta/scripts/InstallPrerequisites-Ubuntu16.04.sh
mkdir shasta-build
cd shasta-build
cmake ../shasta
make all
make install
</pre>




<p>
This creates in the <code>shasta-build</code> directory
a <code>shasta-install</code> directory that 
needs to be copied to the machine where the code will run
and that contains the following:

<ul>
<li>A <code>bin</code> directory containing shared library
<code>shasta.so</code> and several scripts.
<li>A <code>conf</code> directory containing sample config files.
<li>A <code>docs</code> directory containing this and other documentation. 
</ul>

<p>
If your build system has more than one processor
and enough memory, you can speed up the build using the <code>-j</code>
option in the <code>make all</code> command.



<h2>Memory configuration</h2>
<p>
For efficient utilization of the large amount of memory,
the code stores data on non-swappable virtual memory supported by 
2 MB pages, as provided by the 
<a href="https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt">
Linux hugetlbfs filesystem</a>.
Script <code>SetupHugePages.py</code>, 
located in the <code>shasta-install/bin</code> directory, provides an easy 
way to configure memory in this way.

It takes as an argument the number of GB of memory
that should allocated to the hugetlbfs filesystem.
Most of the system memory should be configured in this way, leaving only
20-50 GB of memory allocated to standard 4KB pages.

<p>
Running <code>SetupHugePages.py</code> requires root privileges.
Usually, the simplest and safest way to achieve this is to
use the Linux <code>sudo</code> command.

<p>
After running <code>SetupHugePages.py</code>, run the following
command (shown here with sample output) 
to display the number of 2 MB pages that were
successfully configured:

<pre>
grep HugePages_Total /proc/meminfo
HugePages_Total:  460800
</pre>

The total numnber of pages should equal the number of GB
passed as an argument to <code>SetupHugePages.py</code>
times 512, the number of 2 MB pages in 1 GB.
On a machine that has been running for a long time,
<code>SetupHugePages.py</code> may only be able to
configure less than the requested amount of memory.
This is normal and due to memory fragmentation.
In this case, it may be necessary to reboot the system.



<h2>Setting up a run directory</h2>
<p>
After running <code>SetupHugePages.py</code>, you can create a new directory
to contain your run. After <code>cd</code> to that new directory,
run <code>shasta-install/bin/SetupRunDirectory.py</code>.
This will create symbolic links <code>data</code> and 
<code>Data</code> pointing to filesystems on 4KB and 2MB pages respectively,
as well as a <code>threadLogs</code> directory 
to contain logs for individual threads for assembly phases
that run in parallel.

<p>
Next, you need to create a configuration file where the <code>shasta</code>
software will find values for various assembly parameters.
This configuration file must be named <code>shasta.conf</code>.
Sample configuration files are available in the 
<code>shasta-install/conf</code> directory. 
You can select one of them, copy it to the run directory
under the new name <code>shasta.conf</code>, 
and edit it to customize it as necessary for your run.



<h2>Input files</h2>
<p>
The <code>shasta</code>
software uses as input one or more 
<a href="https://en.wikipedia.org/wiki/FASTA">FASTA</a>
files containing the input reads.
If you have a <a href="https://en.wikipedia.org/wiki/FASTQ">FASTQ</a> file, 
you can convert it to FASTA using script 
<code>shasta-install/bin/FastqToFasta.py</code>.
If your FASTQ file is compressed (extension <code>.gz</code>),
you can decompress it and convert to FASTA in one step,
saving a round trip to disk, using 
script 
<code>shasta-install/bin/FastqGzToFasta.py</code>.

<p>
Usually the input FASTA files will be stored in the run directory,
that is, the same directory that contains
<code>data</code>,
<code>Data</code>, and 
<code>shasta.conf</code>. 
However this is not required.


 
<h2>Running the assembly</h2>
<p>
With the run directory set up as described and the
input FASTA files ready, you can run the assembly.
Just invoke <code>shasta-install/bin/RunAssembly.py</code>,
passing as arguments the names of your input FASTA files,
and the assembly will start.

<p>
To prevent interruptions of the run due to network issues
that break your ssh connection to the machine running the assembly, 
you can use the <code>nohup</code> command:

<pre>
nohup shasta-install/bin/RunAssembly.py Input.fasta 1>RunAssembly.stdout 2>&1 &
</pre>

This way, the assembly runs in the background, is not interrupted
if your ssh connection disappears, and all log output
to <code>stdout</code> and <code>stderr</code>
is saved to file <code>RunAssembly.stdout</code>.

<p>
Because of the large memory utilization, it is recommended
that a machine be dedicated to a single assembly run.
The machine should not be concurrently used for other purposes, 
and multiple concurrent runs on the same machine
are not advisable. 
If the code runs in virtualized or containerized
environments, appropriate amounts of physical resources
should be dedicated to it.
If adequate computational resources are not available,
the assembly run will crash or slow down intolerably,
and potentially crash the entire physical or virtual
machine used.

<p>
Normally, you will be assembling a human genome or
another large genome. For testing purposes,
you can also assemble a small bacterial genome.
Keep in mind, however, that the <code>shasta</code> 
software is not designed or optimized for small genomes.



<h2>Inspecting assembly results</h2>

<p>
Currently, the only output produced by the <code>shasta</code>
software consists of various data structures stored in binary files in memory,
visible as files in the <code>data</code> and <code>Data</code> directories.
The most important such data structure is the global marker graph,
as defined <a href=ShastaSlides-June2018-v2.pdf>here</a>.
The <code>shasta</code>
software implements <code>http</code> functionality 
that allows you to inspect these data structures using a Web browser.
To do this, use the following command:

<pre>
shasta-install/bin/RunServer.py
</pre>

This starts the <code>shasta</code> software in a mode that behaves like an 
<code>http</code> server. You can connect to it by pointing your Web browser to it.
If the browser is running on the same machine where the server is,
enter this URL in your browser:

<pre>
http://localhost:17100
</pre>

(the port number following the colon could change - see the output of the 
<code>RunServer.py</code> command to find out what port the server is using).
If the browser is running on a different machine, you will have to replace
<code>localhost</code> in the above URL with the name or IP address
of the machine where the server is running.

<p>
Once in the browser, the server functionality should
be reasonably self-explanatory. You can look at individual reads
and their markers, and inspect the global marker graph around 
any marker you choose. The local marker graph can be shown
in a detailed format that shows the sequence associated with
each vertex and edge, or in a compact format that shows only the
graph connectivity.



<h2>Saving assembly results</h2>

<p>
The data structures created during assembly are stored in memory,
so they use valuable system resources. In addition, they are
not persistent, which means they are lost 
when the system reboots.
You can save these data structures persistently using the following
command:

<pre>
shasta-install/bin/SaveRun.py
</pre>

This will create directories <code>dataOnDisk</code> and
<code>DataOnDisk</code>
which are copies of <code>data</code> and
<code>Data</code>.
After this command completes, you can delete the 
contents of the <code>data</code> and
<code>Data</code> directory to free the memory 
resources they use. You can still run the <code>http</code> server
using the data on disk, using the following command:

<pre>
shasta-install/bin/RunServerFromDisk.py
</pre>

However, the server will not respond as fast as when running from
data in memory. 

<p>
You can also restore the run in memory from the data on disk at a later time.
For this, make sure the run directory is set up and that the 
<code>data</code> and
<code>Data</code> directories are empty. Then, use the following command:

<pre>
shasta-install/bin/RestoreRun.py
</pre>

At this point, you can again use the <code>RunServer.py</code>
command to run the server from the data just restored to memory.

<p>
The <code>SaveRun.py</code> and <code>RestoreRun.py</code> commands
perform large amounts of sequential I/O to/from storage.
In some environments, the performance of this sequential I/O
can be substantially improved using the following command to
increase the size of individual I/O operations:

<pre>
blockdev --setra 65536 /dev/xvdf
</pre>

Here, replace <code>/dev/xvdf</code> with the name of the block device
that your filesystem is mounted on. The above command
requires root privileges.
The above command is particularly helpful when using
an EBS "Throughput Optimized HDD Volume" (volume type <code>st1</code>) on AWS EC2.


</body>
</html>

